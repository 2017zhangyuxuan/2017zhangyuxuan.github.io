<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png"><link rel="icon" href="/img/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Zhang Yuxuan"><meta name="keywords" content=""><meta name="description" content="本文主要总结了Scott Meyers大牛的 CPU Caches and Why You Care 讲座的主要内容，也顺带回顾了下 CPU Cache 地址映射的相关知识。"><meta property="og:type" content="article"><meta property="og:title" content="CPU Caches and Why You Care"><meta property="og:url" content="https://2017zhangyuxuan.github.io/2023/11/29/2023-11/2023-11-29%20CPU%20Cache/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="本文主要总结了Scott Meyers大牛的 CPU Caches and Why You Care 讲座的主要内容，也顺带回顾了下 CPU Cache 地址映射的相关知识。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312131856853.jpeg"><meta property="article:published_time" content="2023-11-29T03:32:58.000Z"><meta property="article:modified_time" content="2023-12-17T09:07:50.579Z"><meta property="article:author" content="Zhang Yuxuan"><meta property="article:tag" content="CPU"><meta property="article:tag" content="Cache"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312131856853.jpeg"><title>CPU Caches and Why You Care - Hexo</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"2017zhangyuxuan.github.io",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:40,cursorChar:"",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:"41ea7ec25546b456fd8c769b77c5f7b8",google:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"y5CeAktdcKSzcAmVadWC9kvO-gzGzoHsz",app_key:"6DumtsnWAqBVLRmOTnmYxXx6",server_url:"https://y5ceaktd.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!1},gtag:null},search_path:"/local-search.xml",include_content_in_search:!0});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>var _hmt;Fluid.ctx.dnt||(_hmt=_hmt||[],function(){var t=document.createElement("script"),e=(t.src="https://hm.baidu.com/hm.js?41ea7ec25546b456fd8c769b77c5f7b8",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}())</script><meta name="generator" content="Hexo 7.0.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>KingOfDark</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item"><a class="nav-link" href="/links/" target="_self"><i class="iconfont icon-link-fill"></i> <span>友链</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/hexo_img/yourname6.webp) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="CPU Caches and Why You Care"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-11-29 11:32" pubdate>2023年11月29日 中午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>3.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i>12 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">CPU Caches and Why You Care</h1><p id="updated-time" class="note note-info">本文最后更新于：2023年12月17日 下午</p><div class="markdown-body"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近阅读到几篇有关 CPU caches 和 false sharing 的文章，特别是 <em>CPU Caches and Why You Care</em> <sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="[CPU Caches and Why You Care](https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf)">[1]</span></a></sup> ，感觉收获颇丰，对 CPU 缓存有了进一步的了解，所以特此记录下来，下面也给出了对应的PPT链接和演讲视频链接，推荐阅读和观看。同时，又再次接触了Cache的关联映射，大学里学习机组时的记忆从脑海里开始浮现，但我好像已经把知识点都还给老师了，所以借此机会，重新回顾温习一番。</p><p><a target="_blank" rel="noopener" href="https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf">PPT 链接</a> 、<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1HM411A7L9/?spm_id_from=333.337.search-card.all.click&vd_source=caa8e70e79084aa9767fec2791f2ed1d">演进视频</a></p><h1 id="CPU-Caches-and-Why-You-Care"><a href="#CPU-Caches-and-Why-You-Care" class="headerlink" title="CPU Caches and Why You Care"></a>CPU Caches and Why You Care</h1><h2 id="经典问题引入"><a href="#经典问题引入" class="headerlink" title="经典问题引入"></a>经典问题引入</h2><h3 id="行遍历-or-列遍历"><a href="#行遍历-or-列遍历" class="headerlink" title="行遍历 or 列遍历"></a>行遍历 or 列遍历</h3><p>先来看如下代码（左图），函数功能就是对一个矩阵里的元素进行求和，但有两种不同的遍历方式，行遍历和列遍历，右图展示了在 GCC 和 MSVC 环境下行遍历（RW）和列遍历（CM）的遍历时间，可以看到列遍历是明显快于行遍历的，这也是我们平常在遍历二维数组时最常用的方式。那么背后的原因就在于 CPU Cache，因为 cache line 的存在，CPU 每次都会从内存读取一段连续的数据到缓存中，因此在进行列遍历时，下一个访问的数据已经在缓存中，而不需要去内存读取。</p><center><figure class="half"><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121538535.png" srcset="/img/loading.gif" lazyload width="45%"> <img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121539567.png" srcset="/img/loading.gif" lazyload width="45%"><br><em>左: 代码，右: 性能表现</em></figure></center><h3 id="两段-Loop-代码"><a href="#两段-Loop-代码" class="headerlink" title="两段 Loop 代码"></a>两段 Loop 代码</h3><p>再来看看下面这个代码示例<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Gallery of Processor Cache Effects](https://igoro.com/archive/gallery-of-processor-cache-effects/)">[2]</span></a></sup>，两个循环的差异就在于循环的步长不同，Loop 1步长为1，Loop 2步长为16，不难得到 Loop 2的工作量为 Loop 1 的 <strong>6%</strong> 左右，但是实际测试中发现，Loop 2 的耗时是 Loop 1 的 <strong>70%~80%</strong> 左右，这样的结果是反直觉的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">arr</span><span class="hljs-params">(<span class="hljs-number">64</span> * <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>, <span class="hljs-number">0</span>)</span></span>;<br><span class="hljs-comment">// Loop 1</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arr.<span class="hljs-built_in">size</span>(); i++) arr[i] *= <span class="hljs-number">3</span>;<br><br><span class="hljs-comment">// Loop 2</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arr.<span class="hljs-built_in">size</span>(); i+=<span class="hljs-number">16</span>) arr[i] *= <span class="hljs-number">3</span>;<br><br></code></pre></td></tr></table></figure><p>事实上，上述两段代码的运行耗时主要不在于乘法计算，而在于对数组元素的读取，也就是和内存访问相关。因为 CPU Cache Line 的关系（后面会进一步介绍，这里简单来说，就是 CPU 访问内存不是一个字节为单位，而是一个 chunk 大小为单位，目前一般为 64 字节），而 Loop 2 的步长为 16 * 4（int字节数），恰好每次递增都会跳过一个 Cache Line，所以 Loop 2 和 Loop 1 在内存访问上的耗时是接近的。</p><h3 id="指令级并行"><a href="#指令级并行" class="headerlink" title="指令级并行"></a>指令级并行</h3><p>下面这段代码示例同样来自 <a target="_blank" rel="noopener" href="https://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects</a> ，尽管看上去两个循环做的工作量是一样的，但在上述文章中作者指出，Loop 2的执行速度要比 Loop 1 快了两倍，我在 quick_bench 上做了下类似的<a target="_blank" rel="noopener" href="https://quick-bench.com/q/TT7vCjSxsn6fEWzl54ZuUCffpxI">测试</a>（需要关闭优化，不然编译器可能直接把整个循环都优化掉了），结果也表明 Loop 2 要比 Loop 1 快1.6倍左右。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">int</span> steps = <span class="hljs-number">256</span> * <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>;<br><span class="hljs-type">int</span>* a = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[<span class="hljs-number">2</span>];<br><br><span class="hljs-comment">// Loop 1</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;steps; i++) &#123; a[<span class="hljs-number">0</span>]++; a[<span class="hljs-number">0</span>]++; &#125;<br><br><span class="hljs-comment">// Loop 2</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;steps; i++) &#123; a[<span class="hljs-number">0</span>]++; a[<span class="hljs-number">1</span>]++; &#125;<br></code></pre></td></tr></table></figure><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312101541151.png" srcset="/img/loading.gif" lazyload alt="测试结果"></p><p>如何解释这一现象呢？</p><p>实际上对于 Loop 1来说，它的工作流如下图所示，两个 <code>a[0]++</code> 的操作是相互依赖的。</p><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312101540640.png" srcset="/img/loading.gif" lazyload alt="Loop 1 workflow"></p><p>而对于 Loop 2 来说，它的工作流如下图所示， <code>a[0]++</code> 与 <code>a[1]++</code>是可以并行的，而 L1 cache 也支持同时去访问不同的内存单元，做并行的优化。感觉这里其实跟指令流水的概念也很相近。</p><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312101540535.png" srcset="/img/loading.gif" lazyload alt="Loop 2 workflow"></p><h2 id="CPU-Caches"><a href="#CPU-Caches" class="headerlink" title="CPU Caches"></a>CPU Caches</h2><p>上一小节中，列举了几段代码例子，来说明 CPU Caches 的存在以及它的重要性，在该小节中，会进一步介绍 CPU Caches 的缓存结构以及 Cache 的相关知识。</p><h3 id="L1-L2-L3-缓存结构"><a href="#L1-L2-L3-缓存结构" class="headerlink" title="L1,L2,L3 缓存结构"></a>L1,L2,L3 缓存结构</h3><p>介绍 CPU 缓存结构前，先简单了解下计算机金字塔型的存储结构。现代计算机的体系结构，在性能、成本和制造工艺方面做出取舍，从而达到一个平衡。下图是计算机存储结构的示例图，可以看出，访问速度越快一般容量越小，相应的速度越快，成本也会提高。</p><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121603664.jpg" srcset="/img/loading.gif" lazyload alt="计算机存储结构"></p><p>而由于CPU与内存之间存在较大的性能差距，因此引入了 CPU Cache。CPU Cache 通常分为大小不等的三级缓存，分别是 L1 Cache，L2 Cache，L3 Cache，其中 L1 Cache 通常分为数据缓存和指令缓存，即数据和指令时分开存储的；L1 Cache 和 L2 Cache 都是每个 CPU core 独有的，而 L3 Cache 是多个 CPU core 共享的，其层级关系如下图所示：</p><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121613374.png" srcset="/img/loading.gif" lazyload alt="CPU Cache 层级关系（来自小林coding）"></p><hr><p>以 Intel Core i7-9xx 处理器为例，该 CPU 每个 core 有32KB的 L1 I-cache 和 32KB的 L1 D-cache，256KB 的 L2 cache，4 个 cores 共享一个 8MB 的 L3 cache。</p><center><figure class="half"><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121614698.png" srcset="/img/loading.gif" lazyload width="45%"> <img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121615435.png" srcset="/img/loading.gif" lazyload width="45%"><br><em>左: 缓存大小，右: 缓存结构</em></figure></center><h3 id="Cache-line"><a href="#Cache-line" class="headerlink" title="Cache line"></a>Cache line</h3><p>引入CPU cache之后，CPU访问某块地址时，会首先检查L1 Cache，如果不存在，则会检查L2 cache，然后是L3 Cache、内存。如果CPU直接命中cache，则不需要再去访问内存，如果没有命中cache，则需要找到之后会把内存中的数据映射到cache中，内存映射到到cache的传输的最小单位就是 <strong>cache line</strong>。现代CPU cache line大小一般是64或者128字节，也就是说就算CPU只读取一个字节，也会把这个字节所在的内存段里64字节全部映射到cache中。这主要是根据局部性原理，访问到一个地址时，这个地址附近的内容近期也很大概率被访问到。<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="[CPU cache line与多线程性能优化 - 知乎](https://zhuanlan.zhihu.com/p/374586744)">[3]</span></a></sup></p><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121642784.png" srcset="/img/loading.gif" lazyload></p><h3 id="Cache-Coherence"><a href="#Cache-Coherence" class="headerlink" title="Cache Coherence"></a>Cache Coherence</h3><p>现代 CPU 都是多核的，由于 L1&#x2F;L2 Cache 是多个核心各自独有的，那么会带来多核心的<strong>缓存一致性（Cache Coherence）</strong> 的问题，如果不能保证缓存一致性的问题，就可能造成结果错误<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="[CPU 缓存一致性](https://www.xiaolincoding.com/os/1_hardware/cpu_mesi.html)">[4]</span></a></sup>。</p><p>有关CPU 缓存一致性的有关问题，<a target="_blank" rel="noopener" href="https://www.xiaolincoding.com/os/1_hardware/cpu_mesi.html">小林coding - CPU 缓存一致性</a> 这篇文章解释得很详细了，大家可以直接移步阅读，这里不再做进一步展开。</p><h2 id="False-Sharing"><a href="#False-Sharing" class="headerlink" title="False Sharing"></a>False Sharing</h2><p>设想一下，两个不同的变量被两个线程（运行在不同的 core 上）使用，看起来这完全是可以并行的，因为两个线程之间用的是互相独立的数据。然后，如果这两个变量落在同一个 cache line 上的话，并且至少有一个线程进行写操作，那么就会存在 cache line 的竞争（Cache coherence 缓存一致性），这个现象被称作是 <strong>false sharing</strong>。</p><p>之所以称作是 false sharing，是因为尽管不同线程之间没有共享数据，但是无意中共享了 cache line。</p><hr><p>接下来用两段代码来进一步说明 false sharing。</p><p>下方的左图代码，其含义是为了实现对一个矩阵元素求和的功能，使用线程池来并发求和，对应线程数量大小为P，每个线程都会分配一定数量的行，各个线程都会把求和结果放在 <code>result</code> 数组中，最终进行一个求和。</p><p>右图则展示了线程数量与单线程执行效率对比关系，可以看到当线程数小于15时，虽然线程数增加了但程序的执行效率反而低于单线程，线程数在20-25区间也是有一个递减的趋势，且效率远低于预期。</p><center><figure class="half"><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121700695.png" srcset="/img/loading.gif" lazyload width="45%"> <img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121700461.png" srcset="/img/loading.gif" lazyload width="45%"><br><em>左: 代码，右: 性能表现</em></figure></center>导致上述现象的根因就是 false sharing：对于数组 `result[P]`，它的多个 int 数组元素都处在同一个 cache line 上，而在上述代码中，线程池里遍历矩阵元素求和时，都是在对`result[P]`中元素进行修改写入，从而导致多个线程之间对同一个 cache line 产生竞争关系，当一个线程在写入时，其他线程 cache 里的变量已经失效了，必须要重新从内存中读取，因此写线程也需要将写入cache 的值再写回内存。这样一来，由于缓存一致性的问题，导致原先能够并行的多个线程反而像是串行执行，再加上线程切换的开销，因此执行效率自然是大大下降。<p>知道根因后，也就自然想到对应的解决办法，如下左图代码所示，在每个线程中引入一个局部变量 <code>count</code>，在遍历矩阵时都先累加在该变量上，求和完之后再一次地赋值给 <code>result[P]</code>，因此每个线程的局部变量都在不同的线程栈上，是不会处于同一个 cache line 上，因此也就没有缓存一致性和 false sharing 的问题了。最后程序的性能表现如下右图所示，可以看到，达到了一个预期的线性增长的效果。</p><center><figure class="half"><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121702995.png" srcset="/img/loading.gif" lazyload width="45%"> <img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312121702133.png" srcset="/img/loading.gif" lazyload width="45%"><br><em>左: 改进代码，右: 性能表现</em></figure></center><hr><p class="note note-primary">关于 False Sharing ，还可以再看看这篇文章 <a target="_blank" rel="noopener" href="http://simplygenius.net/Article/FalseSharing">Concurrency Hazards: False Sharing</a> <sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Concurrency Hazards: False Sharing](http://simplygenius.net/Article/FalseSharing)">[5]</span></a></sup>，其中也给出了一个详细具体的例子来解释 false sharing。</p><h2 id="总结与建议"><a href="#总结与建议" class="headerlink" title="总结与建议"></a>总结与建议</h2><p>最后也是翻译下PPT里的总结和建议。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><p>小就是快，快就是小，在硬件层面上没有 时间&#x2F;空间 的权衡；</p></li><li><p>关注 locality 局部性</p></li><li><p>可预测的访问模式，构建对缓存预取友好的程序</p></li></ul><h3 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h3><ul><li><p>对于<strong>数据</strong></p><ul><li><p>在实际中，尽可能使用数组遍历</p></li><li><p>充分利用 cache line，提高利用率</p><ul><li>当看到数据结构中有布尔值时，这可能是存在问题的，对于 64位的 cache line 可能就只使用了其中 1 位</li></ul></li><li><p>警惕 false sharing</p></li></ul></li><li><p>对于 <strong>代码&#x2F;指令</strong></p><ul><li><p>适合缓存的工作集：避免在异构序列上进行迭代调用虚函数</p><ul><li>例如从一个基类派生出三个子类 A,B,C，然后有程序了有一个基类指针容器，指向不同类型的子类，当遍历这个容器取调用虚函数 Process 时，第一个对象类型为A，假如此时A对应的Process函数指令不在缓存中，那么就从主存里读取到缓存，然后执行；接着第二个对象类型为B，同样又需要把B的Process函数指令从主存读取到缓存；接着第三个对象类型为C，也需要把C的Process函数指令读取到缓存中，当时如果此时缓存已经满了，那么就会发生替换，很可能就把A之前的缓存的指令替换了。那么以此类推，以A，B，C的顺序访问，那么就会一直发生从主存读取到缓存的操作。一个可行的解决思路就是，按对象类型排好序，先遍历所有 A 对象，再是B，最后是C。</li></ul></li><li><p>构造 “fast paths”，无分支序列：提前检查所有通常不常见的奇怪情况</p></li><li><p>谨慎使用内联函数</p><ul><li>好处在于可以减少分支（函数调用算是分支，可能会产生缓存miss），对编译器来说也便于产生其他类型的优化，来产生更小的代码</li><li>坏处在于缓存中可能会有多份相同代码指令的拷贝，会减小有效缓存的大小</li></ul></li><li><p>利用好一些工具 PGO 和 WPO</p><ul><li>PGO（profile guided optimization） 工具在<em>编译</em>过程中收集程序运行<em>时的</em>数据,然后利用这些数据对程序进行针对性的优化</li><li>WPO（whole program optimization）全局程序优化</li></ul></li></ul></li></ul><h1 id="机组知识回顾：Cache映射"><a href="#机组知识回顾：Cache映射" class="headerlink" title="机组知识回顾：Cache映射"></a>机组知识回顾：Cache映射</h1><p><img src="https://kingofdark-blog.oss-cn-beijing.aliyuncs.com/picture_backend/picture_backend/img/202312131543359.png" srcset="/img/loading.gif" lazyload alt="Cache映射图解"></p><p>上图来自B站视频 <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1N8411y7UF/?spm_id_from=333.788&vd_source=caa8e70e79084aa9767fec2791f2ed1d">帮你把Cache映射梳理清楚! | 图解cache映射</a> <sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="[帮你把Cache映射梳理清楚! | 图解cache映射](https://www.bilibili.com/video/BV1N8411y7UF/?spm_id_from=333.788&vd_source=caa8e70e79084aa9767fec2791f2ed1d)">[6]</span></a></sup>，感觉讲得比较清晰透彻，可以移步观看，这里再做简单地文字版介绍，提炼下关键点。</p><ul><li>引入 Cache 的原因主要为了减小 CPU 和 主存之间的性能差距，这在前面计算机的存储结构部分也有提及。</li><li>Cache 和 主存间的数据交换以 cache行（cache line &#x2F; cache 块）为单位，一个cache line里包含有多个地址（暂且用物理地址表示），而这里一个地址的长度（一个地址对应的数据大小，几个bits），如果是按字节编址，则一个地址代表一字节，如果按字编址，字的大小为4字节的话，则一个地址代表4字节。</li><li>Cache 中每个 cache 行还对应有标记项，包括有效位、脏位、tag （跟地址映射相关）。</li><li>Cache 和 主存之间有三种地址映射方式，且聚焦的是两边<strong>块号</strong>的对应关系（而不是一个地址到另一个地址）。</li><li>对于一个主存物理地址，可以划分成两部分来看，块号和块内地址，块内地址可通过一个块多大和按什么编址来确定<ul><li>全相联映射：多对多映射，主存中的任意一块都可以映射到 Cache 中的任意一行。因此物理地址中除了块内地址部分，其余位都作为 tag 放入 Cache 的标记项，查询 Cache 时需要遍历所有的 cache 行来确定是否在缓存中<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Cache相联映射 - 知乎](https://zhuanlan.zhihu.com/p/530598945)">[7]</span></a></sup><ul><li>优点：机制灵活，命中率高</li><li>缺点：比较电路难于设计和实现，只适合小容量的 Cache</li></ul></li><li>直接映射：一对一映射，主存的某一块一定映射到 Cache 中的某一行<ul><li>优点：映射方式简单，易实现</li><li>缺点：机制不灵活，Cache 命中率低（多个内存块会映射到 Cache 的同一行，容易发生冲突，替换）</li></ul></li><li>组相联映射：结合全相联映射和直接映射的方式，对 Cache 里的 cache line 进行分组，每组有 2<sup>r</sup> 个 cache line（r&#x3D;1,2,3 即2路，4路，8路），即主存中的每个 cache 块都会映射到 Cache 的固定的一个组中，但在组内又可以随机映射到其中一个 cache line。<ul><li>这样设计，增加了映射的灵活性，主存中的一块可以映射到Cache中的2<sup>r</sup> 块，提供命中率，而每次比较时也只需要进行2<sup>r</sup> 路比较，硬件开销小。</li></ul></li></ul></li></ul><p>以上算是泛泛性的概念介绍，更具体的例子可以再参考 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/530598945">Cache相联映射 - 知乎</a> 。</p><hr><p class="note note-primary">在学习 Cache 的时候又想到了 TLB ，就有些疑惑两者的工作顺序是怎样的，简单查阅了下资料， <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/451989743/answer/2802275354"><u>TLB与Cache有什么区别</u></a> 知乎上这里的回答感觉还可以，不过 VIPT 这部分还是没太理解透，后续有机会再仔细研究下。</p><section class="footnotes"><h1>备注/参考</h1><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf">CPU Caches and Why You Care</a> <a href="#fnref:1" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://igoro.com/archive/gallery-of-processor-cache-effects/">Gallery of Processor Cache Effects</a> <a href="#fnref:2" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/374586744">CPU cache line与多线程性能优化 - 知乎</a> <a href="#fnref:3" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.xiaolincoding.com/os/1_hardware/cpu_mesi.html">CPU 缓存一致性</a> <a href="#fnref:4" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a target="_blank" rel="noopener" href="http://simplygenius.net/Article/FalseSharing">Concurrency Hazards: False Sharing</a> <a href="#fnref:5" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1N8411y7UF/?spm_id_from=333.788&vd_source=caa8e70e79084aa9767fec2791f2ed1d">帮你把Cache映射梳理清楚! | 图解cache映射</a> <a href="#fnref:6" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/530598945">Cache相联映射 - 知乎</a> <a href="#fnref:7" rev="footnote" class="footnote-backref">↩</a></span></span></li></ol></div></section></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9F%A5%E8%AF%86/" class="category-chain-item">计算机知识</a> <span>></span> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9F%A5%E8%AF%86/%E7%A1%AC%E4%BB%B6/" class="category-chain-item">硬件</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/CPU/" class="print-no-link">#CPU</a> <a href="/tags/Cache/" class="print-no-link">#Cache</a></div></div><div class="license-box my-3"><div class="license-title"><div>CPU Caches and Why You Care</div><div>https://2017zhangyuxuan.github.io/2023/11/29/2023-11/2023-11-29 CPU Cache/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Zhang Yuxuan</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年11月29日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2023/11/27/2023-11/2023-11-27%20Function%20Objects%20%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/" title="Function Objects 相关问题记录"><span class="hidden-mobile">Function Objects 相关问题记录</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script src="//cdn.jsdelivr.net/npm/@waline/client"></script><div id="waline"></div><script>Fluid.utils.loadComments("#waline",function(){Fluid.utils.createCssLink("https://lib.baomitu.com/waline/2.15.8/waline.min.css"),Fluid.utils.createScript("https://lib.baomitu.com/waline/2.15.8/waline.min.js",function(){var i=Object.assign({serverURL:"https://waline-comment-n2m69ajdb-2017zhangyuxuan.vercel.app",path:"window.location.pathname",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://unpkg.com/@waline/emojis@1.2.0/bmoji"],dark:'html[data-user-color-scheme="dark"]',wordLimit:0,pageSize:10,highlight:!0},{el:"#waline",path:window.location.pathname,serverURL:"https://waline-comment-n2m69ajdb-2017zhangyuxuan.vercel.app/"});Waline.init(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{var i="#waline .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)})})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a><div style="font-size:.85rem"><span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span><script src="/js/duration.js"></script></div></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div><div class="beian"><span><a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">浙ICP备2022004380号-1 </a></span><span><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11011502005551" rel="nofollow noopener" class="beian-police" target="_blank"><span style="visibility:hidden;width:0">|</span> <img src="/img/beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"> <span>京公网安备11011502005551号</span></a></span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,t=t.getElementById("subtitle");t&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>